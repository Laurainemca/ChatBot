{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV4gO2UCQJ1O",
        "outputId": "01422a1f-e3b8-408a-ca99-10beaf35339e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import nltk\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Clj7aNxxQSEj"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gcdguHizRbBD"
      },
      "outputs": [],
      "source": [
        "def save_data(data, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fcJZYQH3RiwF"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "  # Remove special characters and punctuation\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "    return lemmatized_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e7pjFDbLRl35"
      },
      "outputs": [],
      "source": [
        "def get_answer(question, data):\n",
        "    question_tokens = preprocess_text(question)\n",
        "\n",
        "    for key in data:\n",
        "        key_tokens = preprocess_text(key)\n",
        "        if set(key_tokens).issubset(question_tokens):\n",
        "            return data[key]\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "DGEdwQ1oRq_s",
        "outputId": "6475229c-3bf3-4afc-8b4f-240924188e35"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    file_path = 'C:/Users/hp/Git/chatbot/chatInput.json'\n",
        "    data = load_data(file_path)\n",
        "\n",
        "    print(\"Chatbot: Hello! Ask me anything. Type 'quit' to exit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"User: \")\n",
        "\n",
        "        if user_input.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        answer = get_answer(user_input, data)\n",
        "\n",
        "        if answer:\n",
        "            print(\"Chatbot:\", answer)\n",
        "        else:\n",
        "            print(\"Chatbot: I don't know the answer to that. Can you teach me?\")\n",
        "            new_answer = input(\"User: \")\n",
        "            data[user_input] = new_answer\n",
        "            save_data(data, file_path)\n",
        "            print(\"Chatbot: Thank you for teaching me!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
